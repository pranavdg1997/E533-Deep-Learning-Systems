{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "#importing basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "#Importing pytorch functions and modules\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import librosa\n",
    "from librosa.core import stft,istft\n",
    "from sklearn.metrics import *\n",
    "from math import log\n",
    "\n",
    "#Setting random seed for reproducibility\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 2459)\n",
      "(513, 2459)\n",
      "torch.Size([2459, 513])\n"
     ]
    }
   ],
   "source": [
    "s, sr=librosa.load(\"train_clean_male.wav\", sr=None)\n",
    "S_complex=stft(s, n_fft=1024, hop_length=512)\n",
    "x, sr=librosa.load(\"train_dirty_male.wav\", sr=None)\n",
    "X_complex=stft(x, n_fft=1024, hop_length=512)\n",
    "\n",
    "\n",
    "\n",
    "print(X_complex.shape)\n",
    "print(S_complex.shape)\n",
    "\n",
    "X = np.abs(X_complex.T)\n",
    "S = np.abs(S_complex.T)\n",
    "\n",
    "X_dir = np.divide(X_complex,X.T)\n",
    "X = torch.tensor(X).to(device)\n",
    "S = torch.tensor(S).to(device)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining shapes\n",
    "H = 1\n",
    "D = X.shape[1]\n",
    "K = 1\n",
    "\n",
    "H_out = 1\n",
    "D_out = S.shape[1]\n",
    "K_out = 1\n",
    "n_data = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network1d(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            K=K,\n",
    "            H=H,\n",
    "            D=D,\n",
    "            K_out=K_out,\n",
    "            H_out=H_out,\n",
    "            D_out=D_out,\n",
    "            dropout=0.2,\n",
    "    ):\n",
    "        super(Network1d, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = F.relu\n",
    "        \n",
    "        self.K_hidden1 = 5\n",
    "        self.D_hidden1 = 256\n",
    "        self.stride = 2\n",
    "        self.maxp1_K = 2\n",
    "\n",
    "        self.D_last = self.get_conv1d_shape(D_in=D,\n",
    "                                            K_hidden=self.K_hidden1,\n",
    "                                            D_hidden=self.D_hidden1,\n",
    "                                            stride=self.stride,\n",
    "                                            maxp_K=self.maxp1_K)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=K,\n",
    "                               out_channels=self.K_hidden1,\n",
    "                               kernel_size=self.D_hidden1,\n",
    "                               stride=self.stride)\n",
    "        self.maxp1 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(self.K_hidden1*self.D_last,D_out)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxp1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = x.view(-1,self.K_hidden1*self.D_last)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return(x)\n",
    "    \n",
    "    def get_conv1d_shape(self,D_in,K_hidden,D_hidden,stride,maxp_K):\n",
    "        l_out = (D_in - (D_hidden-1) -1)/(stride) + 1\n",
    "        l_out = int(l_out)\n",
    "        l_ans = (l_out - (maxp_K-1) -1)/(maxp_K) + 1\n",
    "        l_ans = int(l_ans)\n",
    "        return(l_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(model,train_dataset,val_dataset,epochs,early_stopping_rounds,batch_size,\n",
    "                         learning_rate,verbose,criterion,eval_func,device):\n",
    "  \n",
    "  \n",
    "    #Dictionary where all the important outputs will be kept\n",
    "    result_dict = dict()\n",
    "    #Reading number of samples in each set\n",
    "    n_train = len(train_dataset)\n",
    "    n_val = len(val_dataset)\n",
    "\n",
    "      # Data loader, using custom user provided batch size\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                                 batch_size=batch_size, \n",
    "                                                 shuffle=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                                 batch_size=n_val, \n",
    "                                                 shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    epoch=1\n",
    "    stop=0\n",
    "    best_performance = -100000\n",
    "    rounds = 0\n",
    "    stop = False\n",
    "    model = model.to(device)\n",
    "\n",
    "      #Training while loop \n",
    "    if(verbose==True):\n",
    "        print(\"Training commenced\")\n",
    "    while ((epoch <= epochs)and(stop==False)):\n",
    "        train_loss = 0\n",
    "        for batch, labels in train_loader:  \n",
    "            # Move tensors to GPU/CPU\n",
    "\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model.forward(batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_batch,val_labels = next(iter(val_loader))\n",
    "            val_batch = val_batch.to(device)\n",
    "            val_labels_pred = model.forward(val_batch).cpu().numpy()\n",
    "\n",
    "            performance = eval_func(val_labels.cpu().numpy(),val_labels_pred)\n",
    "\n",
    "\n",
    "        #Check if we have an increase in performance\n",
    "        if(performance > best_performance):\n",
    "            rounds = 0\n",
    "            best_performance = performance\n",
    "            best_prediction = val_labels_pred\n",
    "            best_state_dict = model.state_dict()\n",
    "            result_dict[\"train_loader\"] = train_loader\n",
    "            result_dict[\"val_batch\"] = val_batch\n",
    "            result_dict[\"val_labels\"] = val_labels\n",
    "            result_dict[\"best_model\"] = model\n",
    "            result_dict[\"val_labels_pred\"] = best_prediction\n",
    "            result_dict[\"best_performance\"] = best_performance\n",
    "        else:\n",
    "            rounds += 1\n",
    "            if(rounds == early_stopping_rounds):\n",
    "                stop = True\n",
    "\n",
    "\n",
    "        #Print statement, every 5 epochs or if it is the last epoch\n",
    "        if(((epoch%5==0)|(stop==True))&(verbose==True)):\n",
    "            print(\"EPOCH:\"+str(epoch))\n",
    "            if(stop==True):\n",
    "                print(\"Training to be concluded after this epoch\") \n",
    "            print(\"Average training loss per sample  = \"+str(train_loss))\n",
    "            print('Performance of the network in current epoch = '+str(round(performance,4)))\n",
    "            print('Best performance of the network yet  = '+str(round(best_performance,4)))\n",
    "\n",
    "\n",
    "        epoch += 1\n",
    "    #While loop ends\n",
    "\n",
    "    print(\"BEST SCORE IS:\"+str(best_performance))\n",
    "\n",
    "\n",
    "\n",
    "    return(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1844, 1, 513])\n",
      "torch.Size([615, 1, 513])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = X.reshape([n_data,1,D])\n",
    "S = S.reshape([n_data,D_out])\n",
    "\n",
    "X_ind = np.array(range(0,n_data))\n",
    "S_ind = np.array(range(0,n_data))\n",
    "\n",
    "X_train_ind,X_val_ind,S_train_ind,S_val_ind = train_test_split(X_ind,S_ind,test_size=0.25,shuffle=True,random_state=SEED)\n",
    "X_train = X[X_train_ind,:,:]\n",
    "print(X_train.shape)\n",
    "X_val = X[X_val_ind,:,:]\n",
    "print(X_val.shape)\n",
    "S_train = S[S_train_ind,:]\n",
    "S_val = S[S_val_ind,:]\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train,S_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val,S_val)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def neg_mean_squared_error(y_true,y_pred):\n",
    "  return((-1)*(mean_squared_error(y_true,y_pred)))\n",
    "\n",
    "#Defining hyper parameters \n",
    "batch_size = 300\n",
    "dropout = 0.2\n",
    "learning_rate = 0.001\n",
    "epochs=200\n",
    "early_stopping_rounds = 10\n",
    "criterion = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training commenced\n",
      "EPOCH:5\n",
      "Average training loss per sample  = 0.4132792465388775\n",
      "Performance of the network in current epoch = -0.0745\n",
      "Best performance of the network yet  = -0.0745\n",
      "EPOCH:10\n",
      "Average training loss per sample  = 0.348116397857666\n",
      "Performance of the network in current epoch = -0.0645\n",
      "Best performance of the network yet  = -0.0645\n",
      "EPOCH:15\n",
      "Average training loss per sample  = 0.291540190577507\n",
      "Performance of the network in current epoch = -0.0526\n",
      "Best performance of the network yet  = -0.0526\n",
      "EPOCH:20\n",
      "Average training loss per sample  = 0.21804503723978996\n",
      "Performance of the network in current epoch = -0.0422\n",
      "Best performance of the network yet  = -0.0422\n",
      "EPOCH:25\n",
      "Average training loss per sample  = 0.18131311796605587\n",
      "Performance of the network in current epoch = -0.0365\n",
      "Best performance of the network yet  = -0.0363\n",
      "EPOCH:30\n",
      "Average training loss per sample  = 0.15034741163253784\n",
      "Performance of the network in current epoch = -0.031\n",
      "Best performance of the network yet  = -0.031\n",
      "EPOCH:35\n",
      "Average training loss per sample  = 0.13632920291274786\n",
      "Performance of the network in current epoch = -0.029\n",
      "Best performance of the network yet  = -0.0285\n",
      "EPOCH:40\n",
      "Average training loss per sample  = 0.12773290369659662\n",
      "Performance of the network in current epoch = -0.0254\n",
      "Best performance of the network yet  = -0.0254\n",
      "EPOCH:45\n",
      "Average training loss per sample  = 0.11631086003035307\n",
      "Performance of the network in current epoch = -0.0248\n",
      "Best performance of the network yet  = -0.0248\n",
      "EPOCH:50\n",
      "Average training loss per sample  = 0.1193888345733285\n",
      "Performance of the network in current epoch = -0.0248\n",
      "Best performance of the network yet  = -0.0238\n",
      "EPOCH:55\n",
      "Average training loss per sample  = 0.12004025001078844\n",
      "Performance of the network in current epoch = -0.0233\n",
      "Best performance of the network yet  = -0.0233\n",
      "EPOCH:60\n",
      "Average training loss per sample  = 0.10869726445525885\n",
      "Performance of the network in current epoch = -0.024\n",
      "Best performance of the network yet  = -0.0217\n",
      "EPOCH:65\n",
      "Average training loss per sample  = 0.10317529737949371\n",
      "Performance of the network in current epoch = -0.023\n",
      "Best performance of the network yet  = -0.0217\n",
      "EPOCH:68\n",
      "Training to be concluded after this epoch\n",
      "Average training loss per sample  = 0.10372784081846476\n",
      "Performance of the network in current epoch = -0.022\n",
      "Best performance of the network yet  = -0.0217\n",
      "BEST SCORE IS:-0.021654466167092323\n"
     ]
    }
   ],
   "source": [
    "cnn1d = Network1d(\n",
    "            K=K,\n",
    "            H=H,\n",
    "            D=D,\n",
    "            K_out=K_out,\n",
    "            H_out=H_out,\n",
    "            D_out=D_out,\n",
    "            dropout=0.2,\n",
    "    )\n",
    "result_dict = train_neural_network(cnn1d,\n",
    "                                   train_dataset,\n",
    "                                   val_dataset,\n",
    "                                   epochs,\n",
    "                                   early_stopping_rounds,\n",
    "                                   batch_size,\n",
    "                                   learning_rate,\n",
    "                                   verbose=True,\n",
    "                                   criterion=criterion,\n",
    "                                   eval_func=neg_mean_squared_error,\n",
    "                                   device=device)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snr(s_actual,s_pred):\n",
    "    num = np.dot(s_actual,s_actual)\n",
    "    den = np.dot((s_actual-s_pred),(s_actual-s_pred))\n",
    "    return(10*log(num/den,10))\n",
    "\n",
    "def get_time_domain_signal(S,S_dir,length):\n",
    "    S_complex = np.multiply(S,S_dir)\n",
    "    return(istft(S_complex, hop_length=512, length = length))\n",
    "\n",
    "def clean_signal(input_file,output_file,model,device):\n",
    "    \"\"\"\n",
    "    params :\n",
    "    input_file = name of input wav file to read\n",
    "    output_file = name of output wav file to write\n",
    "    model = pretrained model object for prediction\n",
    "    device = device(pytorch) on which model is trained\n",
    "    \"\"\"\n",
    "    x, sr=librosa.load(input_file, sr=None)\n",
    "    X_complex=stft(x, n_fft=1024, hop_length=512)\n",
    "    X = np.abs(X_complex.T)\n",
    "\n",
    "\n",
    "    X_dir = np.divide(X_complex,X.T)\n",
    "    X = torch.tensor(X).to(device)\n",
    "    D = X.shape[1]\n",
    "    n_data = X.shape[0]\n",
    "\n",
    "    X = X.reshape([n_data,1,D])\n",
    "\n",
    "    X_clean_pred = model.forward(X).detach().cpu().numpy()\n",
    "\n",
    "    x_clean_pred = get_time_domain_signal(X_clean_pred.T,X_dir,length=len(x))\n",
    "    librosa.output.write_wav(output_file,x_clean_pred, sr)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.016903779\n",
      "SNR = 8.616533193464864\n"
     ]
    }
   ],
   "source": [
    "S_pred = cnn1d.forward(X).detach().cpu().numpy()\n",
    "s_pred = get_time_domain_signal(S_pred.T,X_dir,length=len(x))\n",
    "print(\"Mean Squared Error = \"+str(mean_squared_error(S.cpu().numpy(),S_pred)))\n",
    "print(\"SNR = \"+str(get_snr(s,s_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_signal(\"test_x_01.wav\",\"test_x_01_pred.wav\",cnn1d,device)\n",
    "clean_signal(\"test_x_01.wav\",\"test_x_01_pred.wav\",cnn1d,device)\n",
    "clean_signal(\"test_x_02.wav\",\"test_x_02_pred.wav\",cnn1d,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
